{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "In this notebook, I've explored some ways of dealing with imbalanced datasets along with classification with LogisticRegression.The high level steps are:\n",
    "1. Load the training and validation datasets and clean them\n",
    "    - Convert commas to decimal points\n",
    "    - Drop columns that are missing too many values\n",
    "    - Drop missing value rows if there aren't too many of them\n",
    "    - Apply each action to both datasets\n",
    "2. Create a Pipeline for missing values imputation and Logistic Regression classification\n",
    "    - Using the StandardScaler class that centers data columns to a mean of 0 and STD of 1\n",
    "3. Try the Pipeline classifier on the initial training dataset and get a base performance figure using cross validation\n",
    "4. Try 2 methods of balancing the classes\n",
    "    - Undersampling the majority class so that it matches the minority class\n",
    "    - Oversampling the minority class so that it matches the majority class\n",
    "5. For each of the methods above, the hyberparameter C is tuned using GridSearchCV to reduce overfitting on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sklearn imports\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.preprocessing import StandardScaler, LabelBinarizer, LabelEncoder, OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, GridSearchCV, KFold, StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score\n",
    "from sklearn.utils import resample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import helperFunctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setting the random state for later use\n",
    "random_state = 565"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset and clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Train Set__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainSet = pd.read_csv('training.csv', delimiter=';')\n",
    "trainSet = helperFunctions.cleanData(trainSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainSet = helperFunctions.encodeCategoricals(trainSet, \n",
    "                                                dummyColList=['v1', 'v4', 'v8', 'v9', 'v11', 'v12'], \n",
    "                                                labelCol='classLabel',\n",
    "                                                labelEncoding={'no.':'1', 'yes.':'0'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = trainSet['classLabel']\n",
    "X_train = trainSet.drop('classLabel', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Validation Set__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "validSet = pd.read_csv('validation.csv', delimiter=';')\n",
    "validSet = helperFunctions.cleanData(validSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>v3</th>\n",
       "      <th>v4</th>\n",
       "      <th>v5</th>\n",
       "      <th>v6</th>\n",
       "      <th>v7</th>\n",
       "      <th>v8</th>\n",
       "      <th>v9</th>\n",
       "      <th>v10</th>\n",
       "      <th>v11</th>\n",
       "      <th>v12</th>\n",
       "      <th>v13</th>\n",
       "      <th>v14</th>\n",
       "      <th>classLabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b</td>\n",
       "      <td>32.33</td>\n",
       "      <td>0.000750</td>\n",
       "      <td>u</td>\n",
       "      <td>0.840107</td>\n",
       "      <td>0.544982</td>\n",
       "      <td>1.585</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>t</td>\n",
       "      <td>s</td>\n",
       "      <td>420.0</td>\n",
       "      <td>0</td>\n",
       "      <td>no.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b</td>\n",
       "      <td>23.58</td>\n",
       "      <td>0.000179</td>\n",
       "      <td>u</td>\n",
       "      <td>-4.174396</td>\n",
       "      <td>0.864362</td>\n",
       "      <td>0.540</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>136.0</td>\n",
       "      <td>1</td>\n",
       "      <td>no.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b</td>\n",
       "      <td>36.42</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>y</td>\n",
       "      <td>2.232226</td>\n",
       "      <td>0.627476</td>\n",
       "      <td>0.585</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>240.0</td>\n",
       "      <td>3</td>\n",
       "      <td>no.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b</td>\n",
       "      <td>18.42</td>\n",
       "      <td>0.001041</td>\n",
       "      <td>y</td>\n",
       "      <td>-2.469970</td>\n",
       "      <td>0.846741</td>\n",
       "      <td>0.125</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>120.0</td>\n",
       "      <td>375</td>\n",
       "      <td>no.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b</td>\n",
       "      <td>24.50</td>\n",
       "      <td>0.001334</td>\n",
       "      <td>y</td>\n",
       "      <td>-3.149422</td>\n",
       "      <td>0.321087</td>\n",
       "      <td>0.040</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>120.0</td>\n",
       "      <td>475</td>\n",
       "      <td>no.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  v1     v2        v3 v4        v5        v6     v7 v8 v9  v10 v11 v12    v13  \\\n",
       "0  b  32.33  0.000750  u  0.840107  0.544982  1.585  t  f    0   t   s  420.0   \n",
       "1  b  23.58  0.000179  u -4.174396  0.864362  0.540  f  f    0   t   g  136.0   \n",
       "2  b  36.42  0.000075  y  2.232226  0.627476  0.585  f  f    0   f   g  240.0   \n",
       "3  b  18.42  0.001041  y -2.469970  0.846741  0.125  t  f    0   f   g  120.0   \n",
       "4  b  24.50  0.001334  y -3.149422  0.321087  0.040  f  f    0   t   g  120.0   \n",
       "\n",
       "   v14 classLabel  \n",
       "0    0        no.  \n",
       "1    1        no.  \n",
       "2    3        no.  \n",
       "3  375        no.  \n",
       "4  475        no.  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validSet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "validSet = helperFunctions.encodeCategoricals(validSet, \n",
    "                                                dummyColList=['v1', 'v4', 'v8', 'v9', 'v11', 'v12'], \n",
    "                                                labelCol='classLabel',\n",
    "                                                labelEncoding={'no.':'1', 'yes.':'0'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_valid = validSet['classLabel']\n",
    "X_valid = validSet.drop('classLabel', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure that the train and validation sets have the same columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_valid = helperFunctions.equalizeColumns(X_train, X_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0 - Logistic - Base Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lrPipe0 = Pipeline(steps = [\n",
    "    ('imputer', Imputer(strategy='mean', axis=0)),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('clf', LogisticRegression(random_state=random_state)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    2.1s remaining:    3.3s\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:    2.9s remaining:    1.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Accuracy scores: [ 0.9625      0.96388889  0.96666667  0.95549374  0.95961003]\n",
      "CV score mean: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    3.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    3.7s finished\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(estimator=lrPipe0, X=X_train, y=y_train, n_jobs=-1, scoring='accuracy', verbose=10, cv=5)\n",
    "print('CV Accuracy scores: %s' % scores)\n",
    "print('CV score mean: %.2f' % np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.64102564102564108"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrPipe0 = lrPipe0.fit(X=X_train, y=y_train)\n",
    "accuracy_score(y_pred=lrPipe0.predict(X=X_valid), y_true=y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tune the Regularization parameter strength\n",
    "Looks like the classifier is overfitting on the training set and underperforming on the validation set. We can try to tune the regularization strength by doing a GridSearch on the space of possible values\n",
    "\n",
    "The class_weight parameter is None by default, but by setting it to \"balanced\" we can account for the class imbalance. Including that in the parameter grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.885\n",
      "Best parameters set:\n",
      "\tclf__C: 0.01\n",
      "\tclf__class_weight: None\n",
      "\tclf__penalty: 'l1'\n",
      "\n",
      "\n",
      "Grid scores:\n",
      "0.000 (+/-0.000) for {'clf__C': 1e-05, 'clf__class_weight': None, 'clf__penalty': 'l1'}\n",
      "0.521 (+/-0.033) for {'clf__C': 1e-05, 'clf__class_weight': None, 'clf__penalty': 'l2'}\n",
      "0.000 (+/-0.000) for {'clf__C': 1e-05, 'clf__class_weight': 'balanced', 'clf__penalty': 'l1'}\n",
      "0.193 (+/-0.015) for {'clf__C': 1e-05, 'clf__class_weight': 'balanced', 'clf__penalty': 'l2'}\n",
      "0.000 (+/-0.000) for {'clf__C': 0.0001, 'clf__class_weight': None, 'clf__penalty': 'l1'}\n",
      "0.535 (+/-0.055) for {'clf__C': 0.0001, 'clf__class_weight': None, 'clf__penalty': 'l2'}\n",
      "0.000 (+/-0.000) for {'clf__C': 0.0001, 'clf__class_weight': 'balanced', 'clf__penalty': 'l1'}\n",
      "0.211 (+/-0.015) for {'clf__C': 0.0001, 'clf__class_weight': 'balanced', 'clf__penalty': 'l2'}\n",
      "0.000 (+/-0.000) for {'clf__C': 0.001, 'clf__class_weight': None, 'clf__penalty': 'l1'}\n",
      "0.625 (+/-0.086) for {'clf__C': 0.001, 'clf__class_weight': None, 'clf__penalty': 'l2'}\n",
      "0.493 (+/-0.031) for {'clf__C': 0.001, 'clf__class_weight': 'balanced', 'clf__penalty': 'l1'}\n",
      "0.318 (+/-0.040) for {'clf__C': 0.001, 'clf__class_weight': 'balanced', 'clf__penalty': 'l2'}\n",
      "0.885 (+/-0.167) for {'clf__C': 0.01, 'clf__class_weight': None, 'clf__penalty': 'l1'}\n",
      "0.759 (+/-0.029) for {'clf__C': 0.01, 'clf__class_weight': None, 'clf__penalty': 'l2'}\n",
      "0.440 (+/-0.045) for {'clf__C': 0.01, 'clf__class_weight': 'balanced', 'clf__penalty': 'l1'}\n",
      "0.425 (+/-0.053) for {'clf__C': 0.01, 'clf__class_weight': 'balanced', 'clf__penalty': 'l2'}\n",
      "0.797 (+/-0.076) for {'clf__C': 0.1, 'clf__class_weight': None, 'clf__penalty': 'l1'}\n",
      "0.790 (+/-0.055) for {'clf__C': 0.1, 'clf__class_weight': None, 'clf__penalty': 'l2'}\n",
      "0.454 (+/-0.061) for {'clf__C': 0.1, 'clf__class_weight': 'balanced', 'clf__penalty': 'l1'}\n",
      "0.453 (+/-0.066) for {'clf__C': 0.1, 'clf__class_weight': 'balanced', 'clf__penalty': 'l2'}\n",
      "0.778 (+/-0.053) for {'clf__C': 1.0, 'clf__class_weight': None, 'clf__penalty': 'l1'}\n",
      "0.783 (+/-0.045) for {'clf__C': 1.0, 'clf__class_weight': None, 'clf__penalty': 'l2'}\n",
      "0.454 (+/-0.037) for {'clf__C': 1.0, 'clf__class_weight': 'balanced', 'clf__penalty': 'l1'}\n",
      "0.455 (+/-0.038) for {'clf__C': 1.0, 'clf__class_weight': 'balanced', 'clf__penalty': 'l2'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "param_grid = [{ \n",
    "               'clf__C': [0.00001, 0.0001, 0.001, 0.01, 0.1, 1.0], \n",
    "               'clf__penalty': ['l1', 'l2'],\n",
    "               'clf__class_weight': [None, 'balanced'],\n",
    "              }]\n",
    "\n",
    "# Using a predefined function for gridSearch in helperFunctions\n",
    "helperFunctions.gridSearch(lrPipe0, param_grid, X_train, y_train, scoring='precision')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we want to reduce overfitting, let's choose the C value below 1 that has the best score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Final Validation__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.72820512820512817"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrPipe0.set_params(**{'clf__C':0.1, 'clf__penalty':'l1'})\n",
    "lrPipe0 = lrPipe0.fit(X=X_train, y=y_train)\n",
    "accuracy_score(y_pred=lrPipe0.predict(X=X_valid), y_true=y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So even after regularization tuning, the best we can do is about 68% accuracy on the validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Logistic Regression with Balanced classes - Undersampling Majority Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is one of the methods for class balancing where we reduce the numbers of the majority class samples to match those of the minority class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3328\n",
       "1     269\n",
       "Name: classLabel, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# First resample the majority class to get the same number of samples as the minority class\n",
    "Xdown, ydown = resample(X_train[y_train == 0], y_train[y_train == 0], replace=False, n_samples=X_train[y_train == 1].shape[0])\n",
    "\n",
    "# Now concatenate the resampled majority set to the minority set\n",
    "xBal_Und = pd.concat([X_train[y_train==1], Xdown], axis=0)\n",
    "yBal_Und = pd.concat([y_train[y_train==1], ydown], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lrPipe1 = Pipeline(steps = [\n",
    "    ('imputer', Imputer(missing_values='NaN', strategy='median', axis=0)),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('clf', LogisticRegression(random_state=random_state)),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Training CV__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV scores: [ 0.87962963  0.94444444  0.86111111  0.84259259  0.90566038]\n",
      "CV score mean: 0.89\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(estimator=lrPipe1, X=xBal_Und, y=yBal_Und, n_jobs=-1, scoring='accuracy', \n",
    "                         cv=StratifiedKFold(n_splits=5, random_state=0, shuffle=True,))\n",
    "print('CV scores: %s' % scores)\n",
    "print('CV score mean: %.2f' % np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lrPipe1 = lrPipe1.fit(X=xBal_Und, y=yBal_Und)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Validation Score__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.76923076923076927"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_pred=lrPipe1.predict(X=X_valid), y_true=y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tune the Regularization strength\n",
    "Tuning the regularization parameter using GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.907\n",
      "Best parameters set:\n",
      "\tclf__C: 0.01\n",
      "\tclf__penalty: 'l1'\n",
      "\n",
      "\n",
      "Grid scores:\n",
      "0.000 (+/-0.000) for {'clf__C': 1e-05, 'clf__penalty': 'l1'}\n",
      "0.848 (+/-0.097) for {'clf__C': 1e-05, 'clf__penalty': 'l2'}\n",
      "0.000 (+/-0.000) for {'clf__C': 0.0001, 'clf__penalty': 'l1'}\n",
      "0.850 (+/-0.093) for {'clf__C': 0.0001, 'clf__penalty': 'l2'}\n",
      "0.000 (+/-0.000) for {'clf__C': 0.001, 'clf__penalty': 'l1'}\n",
      "0.860 (+/-0.098) for {'clf__C': 0.001, 'clf__penalty': 'l2'}\n",
      "0.907 (+/-0.095) for {'clf__C': 0.01, 'clf__penalty': 'l1'}\n",
      "0.889 (+/-0.076) for {'clf__C': 0.01, 'clf__penalty': 'l2'}\n",
      "0.889 (+/-0.081) for {'clf__C': 0.1, 'clf__penalty': 'l1'}\n",
      "0.893 (+/-0.081) for {'clf__C': 0.1, 'clf__penalty': 'l2'}\n",
      "0.887 (+/-0.072) for {'clf__C': 1.0, 'clf__penalty': 'l1'}\n",
      "0.887 (+/-0.072) for {'clf__C': 1.0, 'clf__penalty': 'l2'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "param_grid = [{ \n",
    "               'clf__C': [0.00001, 0.0001, 0.001, 0.01, 0.1, 1.0], \n",
    "               'clf__penalty': ['l1', 'l2'],\n",
    "              }]\n",
    "\n",
    "# Using a predefined function for gridSearch in helperFunctions\n",
    "helperFunctions.gridSearch(lrPipe1, param_grid, xBal_Und, yBal_Und, scoring='precision')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we want to reduce overfitting, let's choose the C value below 1 that has the best score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Final Validation__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84615384615384615"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrPipe1.set_params(**{'clf__C':0.01, 'clf__penalty':'l1'})\n",
    "lrPipe1 = lrPipe1.fit(X=xBal_Und, y=yBal_Und)\n",
    "accuracy_score(y_pred=lrPipe1.predict(X=X_valid), y_true=y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Logistic Regression with Balanced classes - Oversampling Minority Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an alternate method of balancing the classes by oversampling the minority class to match the numbers in the majority class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3328\n",
       "1     269\n",
       "Name: classLabel, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# First resample the minority class to get the same number of samples as the majority class\n",
    "X_upsample, y_upsample = resample(X_train[y_train == 1], y_train[y_train == 1], \n",
    "                                  replace=True, n_samples=X_train[y_train == 0].shape[0])\n",
    "\n",
    "# Now concatenate the resampled majority set to the minority set\n",
    "xBal_Ovr = pd.concat([X_train[y_train==0], X_upsample], axis=0)\n",
    "yBal_Ovr = pd.concat([y_train[y_train==0], y_upsample], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    3328\n",
       "0    3328\n",
       "Name: classLabel, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yBal_Ovr.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lrPipe2 = Pipeline(steps = [\n",
    "    ('imputer', Imputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('clf', LogisticRegression(random_state=random_state)),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Training CV__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV scores: [ 0.88738739  0.91441441  0.89339339  0.90840841  0.91891892  0.90990991\n",
      "  0.91891892  0.9009009   0.92018072  0.9246988 ]\n",
      "CV score mean: 0.91\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(estimator=lrPipe2, X=xBal_Ovr, y=yBal_Ovr, n_jobs=-1, scoring='accuracy', \n",
    "                         cv=10)\n",
    "print('CV scores: %s' % scores)\n",
    "print('CV score mean: %.2f' % np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lrPipe2 = lrPipe2.fit(X=xBal_Ovr, y=yBal_Ovr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Validation Score__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.68205128205128207"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_pred=lrPipe2.predict(X=X_valid), y_true=y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__GridSearch Hyperparameter Tuning__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.925\n",
      "Best parameters set:\n",
      "\tclf__C: 0.01\n",
      "\tclf__penalty: 'l1'\n",
      "\n",
      "\n",
      "Grid scores:\n",
      "0.000 (+/-0.000) for {'clf__C': 1e-05, 'clf__penalty': 'l1'}\n",
      "0.873 (+/-0.021) for {'clf__C': 1e-05, 'clf__penalty': 'l2'}\n",
      "0.000 (+/-0.000) for {'clf__C': 0.0001, 'clf__penalty': 'l1'}\n",
      "0.882 (+/-0.022) for {'clf__C': 0.0001, 'clf__penalty': 'l2'}\n",
      "0.924 (+/-0.006) for {'clf__C': 0.001, 'clf__penalty': 'l1'}\n",
      "0.912 (+/-0.019) for {'clf__C': 0.001, 'clf__penalty': 'l2'}\n",
      "0.925 (+/-0.019) for {'clf__C': 0.01, 'clf__penalty': 'l1'}\n",
      "0.919 (+/-0.017) for {'clf__C': 0.01, 'clf__penalty': 'l2'}\n",
      "0.914 (+/-0.016) for {'clf__C': 0.1, 'clf__penalty': 'l1'}\n",
      "0.917 (+/-0.016) for {'clf__C': 0.1, 'clf__penalty': 'l2'}\n",
      "0.917 (+/-0.018) for {'clf__C': 1.0, 'clf__penalty': 'l1'}\n",
      "0.916 (+/-0.018) for {'clf__C': 1.0, 'clf__penalty': 'l2'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "param_grid = [{\n",
    "               'clf__C': [0.00001, 0.0001, 0.001, 0.01, 0.1, 1.0], \n",
    "               'clf__penalty': ['l1', 'l2'],\n",
    "              }]\n",
    "\n",
    "helperFunctions.gridSearch(lrPipe2, param_grid, xBal_Ovr, yBal_Ovr, scoring='precision')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like the best low value for C might be 0.01 with l2 penalty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Final Validation__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85128205128205126"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrPipe2.set_params(**{'clf__C':0.001, 'clf__penalty':'l1'})\n",
    "lrPipe2 = lrPipe2.fit(X=xBal_Ovr, y=yBal_Ovr)\n",
    "accuracy_score(y_pred=lrPipe2.predict(X=X_valid), y_true=y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "The best performance with the Logistic Regression classifier was about 79% accuracy on the validation dataset. This was achieved after adjusting the regularization parameter to reduce overfitting using GridSearch.\n",
    "\n",
    "\n",
    "### Other things that could be tried\n",
    "Obviously, Logistic Regression is just one of many different classification techniques. But I always start with it as it is easy to understand and, with some feature engineering, can give very good results.\n",
    "\n",
    "The next thing to try would be some tree based methods like RandomForests and Boosted Trees to see what kind of accuracy they give."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
