{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "In this notebook, I've explored some classifiers other than Logistic Regression to increase the performance of our predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sklearn imports\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, GridSearchCV, StratifiedKFold, KFold\n",
    "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import helperFunctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setting the random state for later use\n",
    "random_state = 565"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, y_train = helperFunctions.load_clean_encode('training.csv', delimiter=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_valid, y_valid = helperFunctions.load_clean_encode('validation.csv', delimiter=';')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure that the train and validation sets have the same columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_valid = helperFunctions.equalizeColumns(X_train, X_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0 - RandomForests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rfPipe0 = Pipeline(steps = [\n",
    "    ('imputer', Imputer(strategy='mean', axis=0)),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('clf', RandomForestClassifier(random_state=random_state)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    2.2s remaining:    3.4s\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:    3.0s remaining:    2.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Accuracy scores: [ 0.97638889  0.97916667  0.98194444  0.97635605  0.97771588]\n",
      "CV score mean: 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    3.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    3.7s finished\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(estimator=rfPipe0, X=X_train, y=y_train, n_jobs=-1, scoring='accuracy', verbose=10, \n",
    "                         cv=StratifiedKFold(n_splits=5,random_state=random_state, shuffle=False))\n",
    "print('CV Accuracy scores: %s' % scores)\n",
    "print('CV score mean: %.2f' % np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.80000000000000004"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfPipe0 = rfPipe0.fit(X=X_train, y=y_train)\n",
    "accuracy_score(y_pred=rfPipe0.predict(X=X_valid), y_true=y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Try to adjust the parameters to reduce overfitting and also account for unbalanced classes with weight adjustments__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84102564102564104"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfPipe0.set_params(**{ \n",
    "               'clf__n_estimators': 100, \n",
    "               'clf__max_depth': None,\n",
    "               'clf__min_samples_leaf': 20,\n",
    "               'clf__class_weight': 'balanced'\n",
    "              })\n",
    "rfPipe0 = rfPipe0.fit(X=X_train, y=y_train)\n",
    "accuracy_score(y_pred=rfPipe0.predict(X=X_valid), y_true=y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Random Forests - Oversampling Minority Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# First resample the minority class to get the same number of samples as the majority class\n",
    "X_upsample, y_upsample = resample(X_train[y_train == 1], y_train[y_train == 1], \n",
    "                                  replace=True, n_samples=X_train[y_train == 0].shape[0])\n",
    "\n",
    "# Now concatenate the resampled majority set to the minority set\n",
    "xBal_Ovr = pd.concat([X_train[y_train==0], X_upsample], axis=0)\n",
    "yBal_Ovr = pd.concat([y_train[y_train==0], y_upsample], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    3328\n",
       "0    3328\n",
       "Name: classLabel, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yBal_Ovr.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rfPipe2 = Pipeline(steps = [\n",
    "    ('imputer', Imputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('clf', RandomForestClassifier(random_state=random_state)),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Training CV__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV scores: [ 1.          0.9984985   0.9984985   1.          1.          1.          0.9984985\n",
      "  1.          1.          0.99698795]\n",
      "CV score mean: 1.00\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(estimator=rfPipe2, X=xBal_Ovr, y=yBal_Ovr, n_jobs=-1, scoring='accuracy', cv=10)\n",
    "print('CV scores: %s' % scores)\n",
    "print('CV score mean: %.2f' % np.mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Validation Score__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.76923076923076927"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfPipe2 = rfPipe2.fit(X=xBal_Ovr, y=yBal_Ovr)\n",
    "accuracy_score(y_pred=rfPipe2.predict(X=X_valid), y_true=y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__GridSearch Hyperparameter Tuning__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: -0.011\n",
      "Best parameters set:\n",
      "\tclf__max_depth: None\n",
      "\tclf__min_samples_leaf: 1\n",
      "\tclf__n_estimators: 100\n",
      "\n",
      "\n",
      "Grid scores:\n",
      "-0.368 (+/-0.211) for {'clf__max_depth': None, 'clf__min_samples_leaf': 1, 'clf__n_estimators': 1}\n",
      "-0.012 (+/-0.004) for {'clf__max_depth': None, 'clf__min_samples_leaf': 1, 'clf__n_estimators': 20}\n",
      "-0.011 (+/-0.002) for {'clf__max_depth': None, 'clf__min_samples_leaf': 1, 'clf__n_estimators': 50}\n",
      "-0.011 (+/-0.002) for {'clf__max_depth': None, 'clf__min_samples_leaf': 1, 'clf__n_estimators': 100}\n",
      "-0.011 (+/-0.002) for {'clf__max_depth': None, 'clf__min_samples_leaf': 1, 'clf__n_estimators': 150}\n",
      "-0.011 (+/-0.002) for {'clf__max_depth': None, 'clf__min_samples_leaf': 1, 'clf__n_estimators': 200}\n",
      "-0.302 (+/-0.081) for {'clf__max_depth': None, 'clf__min_samples_leaf': 10, 'clf__n_estimators': 1}\n",
      "-0.096 (+/-0.011) for {'clf__max_depth': None, 'clf__min_samples_leaf': 10, 'clf__n_estimators': 20}\n",
      "-0.091 (+/-0.009) for {'clf__max_depth': None, 'clf__min_samples_leaf': 10, 'clf__n_estimators': 50}\n",
      "-0.091 (+/-0.009) for {'clf__max_depth': None, 'clf__min_samples_leaf': 10, 'clf__n_estimators': 100}\n",
      "-0.090 (+/-0.010) for {'clf__max_depth': None, 'clf__min_samples_leaf': 10, 'clf__n_estimators': 150}\n",
      "-0.090 (+/-0.010) for {'clf__max_depth': None, 'clf__min_samples_leaf': 10, 'clf__n_estimators': 200}\n",
      "-0.349 (+/-0.108) for {'clf__max_depth': None, 'clf__min_samples_leaf': 20, 'clf__n_estimators': 1}\n",
      "-0.144 (+/-0.012) for {'clf__max_depth': None, 'clf__min_samples_leaf': 20, 'clf__n_estimators': 20}\n",
      "-0.138 (+/-0.011) for {'clf__max_depth': None, 'clf__min_samples_leaf': 20, 'clf__n_estimators': 50}\n",
      "-0.139 (+/-0.013) for {'clf__max_depth': None, 'clf__min_samples_leaf': 20, 'clf__n_estimators': 100}\n",
      "-0.138 (+/-0.013) for {'clf__max_depth': None, 'clf__min_samples_leaf': 20, 'clf__n_estimators': 150}\n",
      "-0.137 (+/-0.012) for {'clf__max_depth': None, 'clf__min_samples_leaf': 20, 'clf__n_estimators': 200}\n",
      "-0.274 (+/-0.055) for {'clf__max_depth': None, 'clf__min_samples_leaf': 50, 'clf__n_estimators': 1}\n",
      "-0.206 (+/-0.009) for {'clf__max_depth': None, 'clf__min_samples_leaf': 50, 'clf__n_estimators': 20}\n",
      "-0.202 (+/-0.012) for {'clf__max_depth': None, 'clf__min_samples_leaf': 50, 'clf__n_estimators': 50}\n",
      "-0.202 (+/-0.012) for {'clf__max_depth': None, 'clf__min_samples_leaf': 50, 'clf__n_estimators': 100}\n",
      "-0.201 (+/-0.014) for {'clf__max_depth': None, 'clf__min_samples_leaf': 50, 'clf__n_estimators': 150}\n",
      "-0.200 (+/-0.014) for {'clf__max_depth': None, 'clf__min_samples_leaf': 50, 'clf__n_estimators': 200}\n",
      "-0.361 (+/-0.197) for {'clf__max_depth': 10, 'clf__min_samples_leaf': 1, 'clf__n_estimators': 1}\n",
      "-0.040 (+/-0.009) for {'clf__max_depth': 10, 'clf__min_samples_leaf': 1, 'clf__n_estimators': 20}\n",
      "-0.039 (+/-0.007) for {'clf__max_depth': 10, 'clf__min_samples_leaf': 1, 'clf__n_estimators': 50}\n",
      "-0.038 (+/-0.008) for {'clf__max_depth': 10, 'clf__min_samples_leaf': 1, 'clf__n_estimators': 100}\n",
      "-0.038 (+/-0.008) for {'clf__max_depth': 10, 'clf__min_samples_leaf': 1, 'clf__n_estimators': 150}\n",
      "-0.038 (+/-0.008) for {'clf__max_depth': 10, 'clf__min_samples_leaf': 1, 'clf__n_estimators': 200}\n",
      "-0.270 (+/-0.116) for {'clf__max_depth': 10, 'clf__min_samples_leaf': 10, 'clf__n_estimators': 1}\n",
      "-0.102 (+/-0.008) for {'clf__max_depth': 10, 'clf__min_samples_leaf': 10, 'clf__n_estimators': 20}\n",
      "-0.097 (+/-0.009) for {'clf__max_depth': 10, 'clf__min_samples_leaf': 10, 'clf__n_estimators': 50}\n",
      "-0.097 (+/-0.011) for {'clf__max_depth': 10, 'clf__min_samples_leaf': 10, 'clf__n_estimators': 100}\n",
      "-0.097 (+/-0.011) for {'clf__max_depth': 10, 'clf__min_samples_leaf': 10, 'clf__n_estimators': 150}\n",
      "-0.096 (+/-0.011) for {'clf__max_depth': 10, 'clf__min_samples_leaf': 10, 'clf__n_estimators': 200}\n",
      "-0.334 (+/-0.121) for {'clf__max_depth': 10, 'clf__min_samples_leaf': 20, 'clf__n_estimators': 1}\n",
      "-0.145 (+/-0.014) for {'clf__max_depth': 10, 'clf__min_samples_leaf': 20, 'clf__n_estimators': 20}\n",
      "-0.139 (+/-0.012) for {'clf__max_depth': 10, 'clf__min_samples_leaf': 20, 'clf__n_estimators': 50}\n",
      "-0.140 (+/-0.014) for {'clf__max_depth': 10, 'clf__min_samples_leaf': 20, 'clf__n_estimators': 100}\n",
      "-0.139 (+/-0.013) for {'clf__max_depth': 10, 'clf__min_samples_leaf': 20, 'clf__n_estimators': 150}\n",
      "-0.138 (+/-0.013) for {'clf__max_depth': 10, 'clf__min_samples_leaf': 20, 'clf__n_estimators': 200}\n",
      "-0.274 (+/-0.055) for {'clf__max_depth': 10, 'clf__min_samples_leaf': 50, 'clf__n_estimators': 1}\n",
      "-0.207 (+/-0.010) for {'clf__max_depth': 10, 'clf__min_samples_leaf': 50, 'clf__n_estimators': 20}\n",
      "-0.202 (+/-0.011) for {'clf__max_depth': 10, 'clf__min_samples_leaf': 50, 'clf__n_estimators': 50}\n",
      "-0.202 (+/-0.012) for {'clf__max_depth': 10, 'clf__min_samples_leaf': 50, 'clf__n_estimators': 100}\n",
      "-0.201 (+/-0.013) for {'clf__max_depth': 10, 'clf__min_samples_leaf': 50, 'clf__n_estimators': 150}\n",
      "-0.200 (+/-0.014) for {'clf__max_depth': 10, 'clf__min_samples_leaf': 50, 'clf__n_estimators': 200}\n",
      "-0.368 (+/-0.211) for {'clf__max_depth': 50, 'clf__min_samples_leaf': 1, 'clf__n_estimators': 1}\n",
      "-0.012 (+/-0.004) for {'clf__max_depth': 50, 'clf__min_samples_leaf': 1, 'clf__n_estimators': 20}\n",
      "-0.011 (+/-0.002) for {'clf__max_depth': 50, 'clf__min_samples_leaf': 1, 'clf__n_estimators': 50}\n",
      "-0.011 (+/-0.002) for {'clf__max_depth': 50, 'clf__min_samples_leaf': 1, 'clf__n_estimators': 100}\n",
      "-0.011 (+/-0.002) for {'clf__max_depth': 50, 'clf__min_samples_leaf': 1, 'clf__n_estimators': 150}\n",
      "-0.011 (+/-0.002) for {'clf__max_depth': 50, 'clf__min_samples_leaf': 1, 'clf__n_estimators': 200}\n",
      "-0.302 (+/-0.081) for {'clf__max_depth': 50, 'clf__min_samples_leaf': 10, 'clf__n_estimators': 1}\n",
      "-0.096 (+/-0.011) for {'clf__max_depth': 50, 'clf__min_samples_leaf': 10, 'clf__n_estimators': 20}\n",
      "-0.091 (+/-0.009) for {'clf__max_depth': 50, 'clf__min_samples_leaf': 10, 'clf__n_estimators': 50}\n",
      "-0.091 (+/-0.009) for {'clf__max_depth': 50, 'clf__min_samples_leaf': 10, 'clf__n_estimators': 100}\n",
      "-0.090 (+/-0.010) for {'clf__max_depth': 50, 'clf__min_samples_leaf': 10, 'clf__n_estimators': 150}\n",
      "-0.090 (+/-0.010) for {'clf__max_depth': 50, 'clf__min_samples_leaf': 10, 'clf__n_estimators': 200}\n",
      "-0.349 (+/-0.108) for {'clf__max_depth': 50, 'clf__min_samples_leaf': 20, 'clf__n_estimators': 1}\n",
      "-0.144 (+/-0.012) for {'clf__max_depth': 50, 'clf__min_samples_leaf': 20, 'clf__n_estimators': 20}\n",
      "-0.138 (+/-0.011) for {'clf__max_depth': 50, 'clf__min_samples_leaf': 20, 'clf__n_estimators': 50}\n",
      "-0.139 (+/-0.013) for {'clf__max_depth': 50, 'clf__min_samples_leaf': 20, 'clf__n_estimators': 100}\n",
      "-0.138 (+/-0.013) for {'clf__max_depth': 50, 'clf__min_samples_leaf': 20, 'clf__n_estimators': 150}\n",
      "-0.137 (+/-0.012) for {'clf__max_depth': 50, 'clf__min_samples_leaf': 20, 'clf__n_estimators': 200}\n",
      "-0.274 (+/-0.055) for {'clf__max_depth': 50, 'clf__min_samples_leaf': 50, 'clf__n_estimators': 1}\n",
      "-0.206 (+/-0.009) for {'clf__max_depth': 50, 'clf__min_samples_leaf': 50, 'clf__n_estimators': 20}\n",
      "-0.202 (+/-0.012) for {'clf__max_depth': 50, 'clf__min_samples_leaf': 50, 'clf__n_estimators': 50}\n",
      "-0.202 (+/-0.012) for {'clf__max_depth': 50, 'clf__min_samples_leaf': 50, 'clf__n_estimators': 100}\n",
      "-0.201 (+/-0.014) for {'clf__max_depth': 50, 'clf__min_samples_leaf': 50, 'clf__n_estimators': 150}\n",
      "-0.200 (+/-0.014) for {'clf__max_depth': 50, 'clf__min_samples_leaf': 50, 'clf__n_estimators': 200}\n",
      "-0.368 (+/-0.211) for {'clf__max_depth': 100, 'clf__min_samples_leaf': 1, 'clf__n_estimators': 1}\n",
      "-0.012 (+/-0.004) for {'clf__max_depth': 100, 'clf__min_samples_leaf': 1, 'clf__n_estimators': 20}\n",
      "-0.011 (+/-0.002) for {'clf__max_depth': 100, 'clf__min_samples_leaf': 1, 'clf__n_estimators': 50}\n",
      "-0.011 (+/-0.002) for {'clf__max_depth': 100, 'clf__min_samples_leaf': 1, 'clf__n_estimators': 100}\n",
      "-0.011 (+/-0.002) for {'clf__max_depth': 100, 'clf__min_samples_leaf': 1, 'clf__n_estimators': 150}\n",
      "-0.011 (+/-0.002) for {'clf__max_depth': 100, 'clf__min_samples_leaf': 1, 'clf__n_estimators': 200}\n",
      "-0.302 (+/-0.081) for {'clf__max_depth': 100, 'clf__min_samples_leaf': 10, 'clf__n_estimators': 1}\n",
      "-0.096 (+/-0.011) for {'clf__max_depth': 100, 'clf__min_samples_leaf': 10, 'clf__n_estimators': 20}\n",
      "-0.091 (+/-0.009) for {'clf__max_depth': 100, 'clf__min_samples_leaf': 10, 'clf__n_estimators': 50}\n",
      "-0.091 (+/-0.009) for {'clf__max_depth': 100, 'clf__min_samples_leaf': 10, 'clf__n_estimators': 100}\n",
      "-0.090 (+/-0.010) for {'clf__max_depth': 100, 'clf__min_samples_leaf': 10, 'clf__n_estimators': 150}\n",
      "-0.090 (+/-0.010) for {'clf__max_depth': 100, 'clf__min_samples_leaf': 10, 'clf__n_estimators': 200}\n",
      "-0.349 (+/-0.108) for {'clf__max_depth': 100, 'clf__min_samples_leaf': 20, 'clf__n_estimators': 1}\n",
      "-0.144 (+/-0.012) for {'clf__max_depth': 100, 'clf__min_samples_leaf': 20, 'clf__n_estimators': 20}\n",
      "-0.138 (+/-0.011) for {'clf__max_depth': 100, 'clf__min_samples_leaf': 20, 'clf__n_estimators': 50}\n",
      "-0.139 (+/-0.013) for {'clf__max_depth': 100, 'clf__min_samples_leaf': 20, 'clf__n_estimators': 100}\n",
      "-0.138 (+/-0.013) for {'clf__max_depth': 100, 'clf__min_samples_leaf': 20, 'clf__n_estimators': 150}\n",
      "-0.137 (+/-0.012) for {'clf__max_depth': 100, 'clf__min_samples_leaf': 20, 'clf__n_estimators': 200}\n",
      "-0.274 (+/-0.055) for {'clf__max_depth': 100, 'clf__min_samples_leaf': 50, 'clf__n_estimators': 1}\n",
      "-0.206 (+/-0.009) for {'clf__max_depth': 100, 'clf__min_samples_leaf': 50, 'clf__n_estimators': 20}\n",
      "-0.202 (+/-0.012) for {'clf__max_depth': 100, 'clf__min_samples_leaf': 50, 'clf__n_estimators': 50}\n",
      "-0.202 (+/-0.012) for {'clf__max_depth': 100, 'clf__min_samples_leaf': 50, 'clf__n_estimators': 100}\n",
      "-0.201 (+/-0.014) for {'clf__max_depth': 100, 'clf__min_samples_leaf': 50, 'clf__n_estimators': 150}\n",
      "-0.200 (+/-0.014) for {'clf__max_depth': 100, 'clf__min_samples_leaf': 50, 'clf__n_estimators': 200}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "param_grid = [{ \n",
    "               'clf__n_estimators': [1, 20, 50, 100, 150, 200], \n",
    "               'clf__max_depth': [None, 10, 50, 100],\n",
    "               'clf__min_samples_leaf': [1, 10, 20, 50],\n",
    "              }]\n",
    "\n",
    "# Using a predefined function for gridSearch in helperFunctions\n",
    "helperFunctions.gridSearch(rfPipe2, param_grid, xBal_Ovr, yBal_Ovr, scoring='neg_log_loss', cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Final Validation__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the previous GridSearch gave the best parameter as:\n",
    "```\n",
    "\tclf__max_depth: None\n",
    "\tclf__min_samples_leaf: 1\n",
    "\tclf__n_estimators: 100\n",
    "```\n",
    "The best performance was actually at the below parameters. I went through the GridSearch results and choose some parameters that would reduce overfitting and give a more conservative model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83589743589743593"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfPipe2.set_params(**{ \n",
    "               'clf__n_estimators': 200, \n",
    "               'clf__max_depth': 10,\n",
    "               'clf__min_samples_leaf': 50,\n",
    "              })\n",
    "rfPipe2 = rfPipe2.fit(X=xBal_Ovr, y=yBal_Ovr)\n",
    "accuracy_score(y_pred=rfPipe2.predict(X=X_valid), y_true=y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "The best performance with the RandomForests classifier was about 84% accuracy on the validation dataset. This was achieved after adjusting the parameters to reduce overfitting.\n",
    "\n",
    "RandomForests is actually not affected by class imbalanced too much and this is evident in the 2 rounds shown above.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
